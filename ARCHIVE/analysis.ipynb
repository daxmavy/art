{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecba3495",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174c8244",
   "metadata": {},
   "source": [
    "# Research Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf78954",
   "metadata": {},
   "source": [
    "## Joint inference across both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2480d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(zip(diff_model_one_hot, reasons))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492e4399",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChoiceReasonTuplePredictor(nn.Module):  # inheriting from nn.Module!\n",
    "\n",
    "    def __init__(self, num_terms, num_aspects):\n",
    "\n",
    "        super(ChoiceReasonTuplePredictor, self).__init__()\n",
    "\n",
    "        self.linear = nn.Linear(num_terms, num_aspects, bias=False)\n",
    "\n",
    "    def forward(self, covariates):\n",
    "        choice_prob = F.sigmoid(torch.sum(self.linear(covariates)))\n",
    "        reason_log_prob = F.log_softmax(self.linear(covariates))\n",
    "        return choice_prob, reason_log_prob\n",
    "\n",
    "model = ChoiceReasonTuplePredictor(num_terms=2, num_aspects=6)\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "losses_total = []\n",
    "losses_choice = []\n",
    "losses_reason = []\n",
    "for epoch in range(100):\n",
    "    running_loss_choice = 0\n",
    "    running_loss_reason = 0\n",
    "    running_loss_total = 0\n",
    "    for instance_covariates, reason_idx in data:\n",
    "        model.zero_grad()\n",
    "        # forward pass\n",
    "        choice_prob, reason_log_prob = model(torch.from_numpy(instance_covariates).float())\n",
    "\n",
    "        choice_loss = F.binary_cross_entropy(choice_prob, torch.ones_like(choice_prob))\n",
    "        reason_loss = F.nll_loss(reason_log_prob, torch.tensor(reason_idx))  \n",
    "        loss_total =  (choice_loss + 10 * reason_loss) / 11\n",
    "        loss_total.backward()\n",
    "        running_loss_choice += choice_loss.item()\n",
    "        running_loss_reason += reason_loss.item()\n",
    "        running_loss_total += loss_total.item()\n",
    "        optimizer.step()\n",
    "    losses_total.append(running_loss_total / len(data))\n",
    "    losses_choice.append(running_loss_choice / len(data))\n",
    "    losses_reason.append(running_loss_reason / len(data))\n",
    "\n",
    "plt.plot(losses_total, label='total')\n",
    "plt.plot(losses_choice, label='choice')\n",
    "plt.plot(losses_reason, label='reason')\n",
    "plt.legend()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
